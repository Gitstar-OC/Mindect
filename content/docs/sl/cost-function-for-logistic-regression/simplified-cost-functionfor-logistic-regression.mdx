---
title: Simplified Cost Function for Logistic Regression
---

## Introduction

In the last part, we explored the **loss function** and the **cost function** for logistic regression. In this part, you'll learn a slightly simpler way to express these functions, which will make the implementation smoother when we get to **gradient descent** for fitting the parameters of a logistic regression model.

Let’s begin by revisiting the loss function from the previous section.

![SCFLR (1)](/SL/CFLR/SCFLR%20(1).png)

## Simplifying the Loss Function

Since we're dealing with a **binary classification problem**, where `y` can only take the values `0` or `1`, we can rewrite the loss function in a simpler form. This simpler version still accurately reflects the relationship between the prediction and the target label.

Here’s how the **simplified loss function** looks:

![SCFLR (2)](/SL/CFLR/SCFLR%20(2).png)

Given a prediction `f(x)` and a target label `y`, the **loss** can be defined as:

```math
Loss = -[y * \log(f(x)) + (1 - y) * \log(1 - f(x))]
```

This expression, while concise, is equivalent to the more complex formulation we previously used. Let’s break down why this works by considering the possible values of `y`.

## Case 1: When y = 1

Let’s examine the scenario where `y = 1`.

In this case, the first term is `1`, and the second term becomes `0` (because `1 - y = 0`).

The loss reduces to:

```math
Loss = - \log(f(x))
```

This is exactly equivalent to the original loss function in this case.

## Case 2: When y = 0

Now let’s look at the case where `y = 0`.

Here, the first term becomes `0`, and the second term is `1 - y = 1`.

The loss function becomes:

```math
Loss = - \log(1 - f(x))
```

This is again consistent with the original, more complex formula. As a result, no matter whether `y = 0` or `y = 1`, this simpler loss function yields the correct result.

## The Cost Function for Logistic Regression

We can now apply this simplified loss function to define the **cost function** for logistic regression. As a reminder, the cost function `J` is the **average loss** across the training set of `m` examples.

Here is the **simplified loss function**:

![SCFLR (6)](/SL/CFLR/SCFLR%20(6).png)

The cost function is defined as:

```math
J(\theta) = \frac{1}{m} \sum_{i=1}^{m} \left[ -y^{(i)} \log(f(x^{(i)})) - (1 - y^{(i)}) \log(1 - f(x^{(i)})) \right]
```

You can bring out the negative signs and simplify it as follows:

![SCFLR (7)](/SL/CFLR/SCFLR%20(7).png)

This is the cost function used to train logistic regression models. It’s widely adopted because it is derived from the **maximum likelihood estimation** principle from statistics, which ensures that this cost function is **convex**.

![SCFLR (8)](/SL/CFLR/SCFLR%20(8).png)

You don't need to dive into the details of **maximum likelihood estimation** for now. Just know that this cost function has a nice property of being convex, meaning we can apply gradient descent efficiently.

```js
// this code is used for writing javascript in it and will show nothing other than javascript code in various colors 
```

## Next Steps

The upcoming notebook will show how this cost function is implemented in code. I recommend you take a look because you will be implementing it later during the practical lab. The notebook also demonstrates how different parameter choices affect the cost.

The plot shows how the better fitting **blue decision boundary** has a lower cost relative to the **magenta decision boundary**. With this simplified cost function, we are now ready to jump into applying gradient descent to logistic regression.

{/*
---
title: Simplified Cost Function for Logistic Regression
---


In the last part you saw the loss function and the cost function for logistic regression. In this part you'll see a slightly simpler way to write out the loss and cost functions, so that the implementation can be a bit simpler when we get to gradient descent for fitting the parameters of a logistic regression model.

Let's take a look. As a reminder, here is the loss function that we had defined in the previous part for logistic regression.
![SCFLR (1)](/SL/CFLR/SCFLR%20(1).png)

Because we're still working on a binary classification problem, `y is either zero or one`. Because y is either zero or one and cannot take on any value other than zero or one, we'll be able to come up with a simpler way to write this loss function. You can write the loss function as follows.

![SCFLR (2)](/SL/CFLR/SCFLR%20(2).png)

Given a prediction `f of x and the target label y`, the `loss equals negative y times log of f minus 1 minus y times log of 1 minus f`. It turns out this equation, which we just wrote in one line, is completely equivalent to this more complex formula up here. Let's see why this is the case. Remember, y can only take on the values of either one or zero.

In the first case, let's say y equals 1. This first y over here is one and this 1 minus y is 1 minus 1, which is therefore equal to 0. So the loss becomes negative 1 times log of f of x minus 0 times a bunch of stuff.

![SCFLR (4)](/SL/CFLR/SCFLR%20(4).png)

That becomes zero and goes away. `When y is equal to 1, the loss is indeed the first term on top, negative log of f of x`.

Let's look at the second case, when y is equal to 0. In this case, this y here is equal to 0, so this first term goes away, and the second term is 1 minus 0 times that logarithmic term. The loss becomes this `negative 1 times log of 1 minus f of x`.

![SCFLR (5)](/SL/CFLR/SCFLR%20(5).png)

That's just equal to this second term up here. In the case of y equals 0, we also get back the original loss function as defined above. What you see is that whether y is one or zero, this single expression here is equivalent to the more complex expression up here, which is why this gives us a simpler way to write the loss with just one equation without separating out these two cases, like we did on top. Using this simplified loss function, let's go back and write out the cost function for logistic regression.

Here again is the simplified loss function. Recall that the cost J is just the average loss, average across the entire training set of m examples.

![SCFLR (6)](/SL/CFLR/SCFLR%20(6).png)

So it's 1 over m times the sum of the loss from i equals 1 to m. If you plug in the definition for the simplified loss from above, then it looks like this, 1 over m times the sum of this term above. If you bring the negative signs and move them outside, then you end up with this expression over here,
![SCFLR (7)](/SL/CFLR/SCFLR%20(7).png)

and this is the cost function. `The cost function that pretty much everyone uses to train logistic regression`. You might be wondering, why do we choose this particular function when there could be tons of other costs functions we could have chosen? Although we won't have time to go into great detail on this in this class, I'd just like to mention that this particular cost function is derived from statistics using a statistical principle called `maximum likelihood estimation`, which is an idea from statistics on how to efficiently find parameters for different models. This cost function has the nice property that it is `convex`.

![SCFLR (8)](/SL/CFLR/SCFLR%20(8).png)

But don't worry about learning the details of `maximum likelihood`. It's just a deeper rationale and justification behind this particular cost function.


The upcoming notebook will show you how the logistic cost function is implemented in code. I recommend taking a look at it, because you implement this later into practice lab at the end of the week. This upcoming notebook also shows you how two different choices of the parameters will lead to different cost calculations. You can see in the plot that the better fitting blue decision boundary has a lower cost relative to the magenta decision boundary. So with the simplified cost function, we're now ready to jump into applying gradient descent to logistic regression.
*/}